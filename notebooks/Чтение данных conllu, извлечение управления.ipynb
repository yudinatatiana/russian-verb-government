{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import conllu\n",
    "import json\n",
    "import csv\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_conllu(text):\n",
    "    try: \n",
    "        result = [tokenlist for tokenlist in conllu.parse(text)]\n",
    "        return result[0]\n",
    "    except:\n",
    "        return None ## сюда можно подставить свой собственный разбор"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_conllu_data(filename):\n",
    "    with open(filename, 'r', encoding='UTF-8') as f:  \n",
    "        flag = False\n",
    "        result_sent_list = list()\n",
    "        temp_list = list()\n",
    "\n",
    "        while True: \n",
    "            line = f.readline()\n",
    "            if not line:  # достигли конца файла\n",
    "                parse_result = parse_conllu(\"\".join(temp_list))\n",
    "                if parse_result is not None:\n",
    "                    result_sent_list.append(parse_result)\n",
    "                return result_sent_list\n",
    "            if line[:6] == \"# text\":\n",
    "                if flag is False:  # начинаем считывать новое предложение\n",
    "                    flag = True\n",
    "                else:  # достигли конца разбора предложения\n",
    "                    flag = False\n",
    "                    parse_result = parse_conllu(\"\".join(temp_list))\n",
    "                    if parse_result is not None:\n",
    "                        result_sent_list.append(parse_result)\n",
    "                    temp_list = list()\n",
    "            temp_list.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VerbGovernment:\n",
    "    \"\"\"Глагольное управление: глагол/деепричастие/причастие + (предлог) + существительное; падеж\"\"\"\n",
    "    \n",
    "    def __init__(self, sent, noun, verb):\n",
    "        self.noun = noun\n",
    "        self.verb = verb\n",
    "        self.part = self.__find_adp_or_part__(sent, verb['id'], 'PART')\n",
    "        self.adp = self.__find_adp_or_part__(sent, noun['id'], 'ADP')\n",
    "        self.case = self.__find_case__(noun)\n",
    "        \n",
    "    def __find_adp_or_part__(self, sent, head_id, pos):\n",
    "        for i in range(head_id - 1, -1, -1):\n",
    "            if sent[i]['upos'] == pos and int(sent[i]['head']) == int(head_id):\n",
    "                if pos == 'PART' and sent[i]['lemma'] == 'не':\n",
    "                    return sent[i]['lemma']\n",
    "                elif pos == 'ADP':\n",
    "                    return sent[i]['lemma']\n",
    "        return '_'\n",
    "    \n",
    "    def __find_case__(self, token):\n",
    "        try:\n",
    "            return token['feats']['Case']\n",
    "        except:\n",
    "            return '_'\n",
    "        \n",
    "    def show(self):\n",
    "        print(self.part, self.verb['form'], self.adp, self.noun['form'], self.case)\n",
    "        \n",
    "    def dict_of_forms(self):\n",
    "        res_dict = {\n",
    "            'part': self.part,\n",
    "            'verb': self.verb['form'].lower(),\n",
    "            'adp': self.adp,\n",
    "            'noun': self.noun['form'].lower(),\n",
    "            'case': self.case\n",
    "        }\n",
    "        return res_dict\n",
    "    \n",
    "    def dict_of_lemmas(self):\n",
    "        res_dict = {\n",
    "            'part': self.part,\n",
    "            'verb': self.verb['lemma'],\n",
    "            'adp': self.adp,\n",
    "            'noun': self.noun['lemma'],\n",
    "            'case': self.case\n",
    "        }\n",
    "        return res_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.dict_of_lemmas = dict()\n",
    "        self.list_of_forms = list()\n",
    "        self.count_parsed = 0\n",
    "        self.count_error = 0\n",
    "        \n",
    "        self.__read_conllu_data__(filename)\n",
    "        self.stat = self.__calculate__()\n",
    "        \n",
    "    def __parse_conllu__(self, text):\n",
    "        try: \n",
    "            result = [tokenlist for tokenlist in conllu.parse(text)]\n",
    "            return result[0]\n",
    "        except:\n",
    "            return None ## сюда можно подставить свой собственный разбор\n",
    "        \n",
    "    def __find_verb_government__(self, sent):\n",
    "        for token in sent:\n",
    "            if token['upos'] == 'NOUN' and sent[token['head'] - 1]['upos'] == 'VERB':\n",
    "                vg = VerbGovernment(sent, token, sent[token['head'] - 1])\n",
    "                self.list_of_forms.append(vg.dict_of_forms())\n",
    "                self.__update_dict_of_lemmas__(vg.dict_of_lemmas())\n",
    "                \n",
    "    def __update_dict_of_lemmas__(self, vg):\n",
    "        if vg['part'] not in self.dict_of_lemmas:\n",
    "            self.dict_of_lemmas[vg['part']] = dict()\n",
    "        if vg['verb'] not in self.dict_of_lemmas[vg['part']]:\n",
    "            self.dict_of_lemmas[vg['part']][vg['verb']] = dict()\n",
    "        if vg['adp'] not in self.dict_of_lemmas[vg['part']][vg['verb']]:\n",
    "            self.dict_of_lemmas[vg['part']][vg['verb']][vg['adp']] = dict()\n",
    "        if vg['case'] not in self.dict_of_lemmas[vg['part']][vg['verb']][vg['adp']]:\n",
    "            self.dict_of_lemmas[vg['part']][vg['verb']][vg['adp']][vg['case']] = dict()\n",
    "        if vg['noun'] not in self.dict_of_lemmas[vg['part']][vg['verb']][vg['adp']][vg['case']]:\n",
    "            self.dict_of_lemmas[vg['part']][vg['verb']][vg['adp']][vg['case']][vg['noun']] = 1\n",
    "        else:\n",
    "            self.dict_of_lemmas[vg['part']][vg['verb']][vg['adp']][vg['case']][vg['noun']] += 1\n",
    "        \n",
    "    def __read_conllu_data__(self, filename):\n",
    "        with open(filename, 'r', encoding='UTF-8') as f:  \n",
    "            flag = False\n",
    "            temp_list = list()\n",
    "\n",
    "            while True: \n",
    "                line = f.readline()\n",
    "                if not line:  # достигли конца файла\n",
    "                    parse_result = self.__parse_conllu__(\"\".join(temp_list))\n",
    "                    if parse_result is not None:\n",
    "                        self.__find_verb_government__(parse_result)\n",
    "                        self.count_parsed += 1\n",
    "                    else:\n",
    "                        self.count_error += 1\n",
    "                    return 0\n",
    "                if line[:6] == \"# text\":\n",
    "                    if flag is False:  # начинаем считывать новое предложение\n",
    "                        flag = True\n",
    "                    else:  # достигли конца разбора предложения\n",
    "                        flag = False\n",
    "                        parse_result = self.__parse_conllu__(\"\".join(temp_list))\n",
    "                        if parse_result is not None:\n",
    "                            self.__find_verb_government__(parse_result)\n",
    "                            self.count_parsed += 1\n",
    "                        else:\n",
    "                            self.count_error += 1\n",
    "                        temp_list = list()\n",
    "                temp_list.append(line)\n",
    "                \n",
    "    def __count_verb__(self, part):\n",
    "        try:\n",
    "            count = len(self.dict_of_lemmas[part])\n",
    "        except:\n",
    "            count = 0\n",
    "        return count\n",
    "                \n",
    "    def __calculate__(self):       \n",
    "        result_dict = {\n",
    "            \"corpus_name\": self.filename.split('/')[-1],\n",
    "            \"count_sent\" : self.count_parsed + self.count_error,\n",
    "            \"count_parsed_sent\": self.count_parsed, \n",
    "            \"count_error_sent\": self.count_error,\n",
    "            \"count_vg\": len(self.list_of_forms), \n",
    "            \"verb_\": self.__count_verb__(\"_\"), \n",
    "            \"verb_not\": self.__count_verb__(\"не\") \n",
    "        }\n",
    "        return result_dict\n",
    "    \n",
    "    def __new_filename__(self, ext):\n",
    "        parts = self.filename.split('conllu')\n",
    "        new_filename = parts[0][:-1] + parts[1] + ext\n",
    "        return new_filename\n",
    "        \n",
    "    def save_dict_to_json(self, json_filename=None):\n",
    "        if json_filename is None:\n",
    "            json_filename = self.__new_filename__('json')\n",
    "        \n",
    "        with open(json_filename, 'w', encoding='UTF-8') as f:\n",
    "            json.dump(self.dict_of_lemmas, f)\n",
    "    \n",
    "    def save_list_to_csv(self, csv_filename=None):\n",
    "        if csv_filename is None:\n",
    "            csv_filename = self.__new_filename__('csv')\n",
    "            \n",
    "        keys = self.list_of_forms[0].keys()\n",
    "        \n",
    "        with open(csv_filename, 'w', encoding='UTF-8', newline='') as f:\n",
    "            dict_writer = csv.DictWriter(f, keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(self.list_of_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dir_res = './data/'\n",
    "data_res = os.listdir(path_to_dir_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 из 26\n",
      "Корпус: articles6_2.conllu\n",
      "\n",
      "Всего предложений: 13608\n",
      "\tРазобрано: 13608\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 29057\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 2416\n",
      "\tС \"не\": 412\n",
      "___________________________________________\n",
      "2 из 26\n",
      "Корпус: articles_Vestnik_rayona.conllu\n",
      "\n",
      "Всего предложений: 10412\n",
      "\tРазобрано: 10159\n",
      "\tС ошибками парсинга: 253\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 23423\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 2236\n",
      "\tС \"не\": 294\n",
      "___________________________________________\n",
      "3 из 26\n",
      "Корпус: compulenta-2013.txt.conllu\n",
      "\n",
      "Всего предложений: 472577\n",
      "\tРазобрано: 472577\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 1330600\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 10705\n",
      "\tС \"не\": 2818\n",
      "___________________________________________\n",
      "4 из 26\n",
      "Корпус: compulenta-2013_short.txt.conllu\n",
      "\n",
      "Всего предложений: 36199\n",
      "\tРазобрано: 36199\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 117246\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 3961\n",
      "\tС \"не\": 747\n",
      "___________________________________________\n",
      "5 из 26\n",
      "Корпус: detective_for_kidds.txt.conllu\n",
      "\n",
      "Всего предложений: 617693\n",
      "\tРазобрано: 617693\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 742021\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 14840\n",
      "\tС \"не\": 3882\n",
      "___________________________________________\n",
      "6 из 26\n",
      "Корпус: detective_masters.txt.conllu\n",
      "\n",
      "Всего предложений: 1208062\n",
      "\tРазобрано: 1208062\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 1688249\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 16569\n",
      "\tС \"не\": 5500\n",
      "___________________________________________\n",
      "7 из 26\n",
      "Корпус: dvnovosti.ru_khab.conllu\n",
      "\n",
      "Всего предложений: 8955\n",
      "\tРазобрано: 8955\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 30567\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 2905\n",
      "\tС \"не\": 519\n",
      "___________________________________________\n",
      "8 из 26\n",
      "Корпус: fontanka.txt.conllu\n",
      "\n",
      "Всего предложений: 1134905\n",
      "\tРазобрано: 1134905\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 2619499\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 13199\n",
      "\tС \"не\": 4320\n",
      "___________________________________________\n",
      "9 из 26\n",
      "Корпус: gazeta-4-ru-2020.txt.conllu\n",
      "\n",
      "Всего предложений: 587682\n",
      "\tРазобрано: 587682\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 1552417\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 10648\n",
      "\tС \"не\": 3335\n",
      "___________________________________________\n",
      "10 из 26\n",
      "Корпус: gazeta-4-ru-2020_short.txt.conllu\n",
      "\n",
      "Всего предложений: 182035\n",
      "\tРазобрано: 182035\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 487111\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 7436\n",
      "\tС \"не\": 2054\n",
      "___________________________________________\n",
      "11 из 26\n",
      "Корпус: gazeta_3_ru-2018.conllu\n",
      "\n",
      "Всего предложений: 261283\n",
      "\tРазобрано: 261283\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 680271\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 8607\n",
      "\tС \"не\": 2530\n",
      "___________________________________________\n",
      "12 из 26\n",
      "Корпус: gorky[ru]_2-2018.conllu\n",
      "\n",
      "Всего предложений: 72523\n",
      "\tРазобрано: 72523\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 160873\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 7889\n",
      "\tС \"не\": 1705\n",
      "___________________________________________\n",
      "13 из 26\n",
      "Корпус: habarahabr_2017.txt.conllu\n",
      "\n",
      "Всего предложений: 1060644\n",
      "\tРазобрано: 1060643\n",
      "\tС ошибками парсинга: 1\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 1860035\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 18565\n",
      "\tС \"не\": 5074\n",
      "___________________________________________\n",
      "14 из 26\n",
      "Корпус: ibusines.txt.conllu\n",
      "\n",
      "Всего предложений: 315901\n",
      "\tРазобрано: 315901\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 776580\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 10202\n",
      "\tС \"не\": 2928\n",
      "___________________________________________\n",
      "15 из 26\n",
      "Корпус: kosterin72ru.txt.conllu\n",
      "\n",
      "Всего предложений: 485956\n",
      "\tРазобрано: 485956\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 1505408\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 11794\n",
      "\tС \"не\": 3628\n",
      "___________________________________________\n",
      "16 из 26\n",
      "Корпус: membrana.txt.conllu\n",
      "\n",
      "Всего предложений: 189020\n",
      "\tРазобрано: 189020\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 589307\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 9969\n",
      "\tС \"не\": 2590\n",
      "___________________________________________\n",
      "17 из 26\n",
      "Корпус: naked-science.txt.conllu\n",
      "\n",
      "Всего предложений: 218081\n",
      "\tРазобрано: 218081\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 584451\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 7851\n",
      "\tС \"не\": 2028\n",
      "___________________________________________\n",
      "18 из 26\n",
      "Корпус: rosbalt_2.conllu\n",
      "\n",
      "Всего предложений: 227092\n",
      "\tРазобрано: 227092\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 601898\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 7264\n",
      "\tС \"не\": 1988\n",
      "___________________________________________\n",
      "19 из 26\n",
      "Корпус: str_fives.txt.conllu\n",
      "\n",
      "Всего предложений: 30818\n",
      "\tРазобрано: 30818\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 66438\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 5511\n",
      "\tС \"не\": 1053\n",
      "___________________________________________\n",
      "20 из 26\n",
      "Корпус: syntagrus-deeppavlov.txt.conllu\n",
      "\n",
      "Всего предложений: 70801\n",
      "\tРазобрано: 70801\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 53801\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 5191\n",
      "\tС \"не\": 877\n",
      "___________________________________________\n",
      "21 из 26\n",
      "Корпус: texts_h_100w.txt.conllu\n",
      "\n",
      "Всего предложений: 57507\n",
      "\tРазобрано: 57507\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 126760\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 6341\n",
      "\tС \"не\": 1177\n",
      "___________________________________________\n",
      "22 из 26\n",
      "Корпус: texts_h_100w_val.txt.conllu\n",
      "\n",
      "Всего предложений: 9681\n",
      "\tРазобрано: 9681\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 21309\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 2812\n",
      "\tС \"не\": 351\n",
      "___________________________________________\n",
      "23 из 26\n",
      "Корпус: texts_m_100w.txt.conllu\n",
      "\n",
      "Всего предложений: 54153\n",
      "\tРазобрано: 54153\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 118148\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 4721\n",
      "\tС \"не\": 861\n",
      "___________________________________________\n",
      "24 из 26\n",
      "Корпус: texts_m_100w_val.txt.conllu\n",
      "\n",
      "Всего предложений: 8909\n",
      "\tРазобрано: 8909\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 19812\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 2062\n",
      "\tС \"не\": 238\n",
      "___________________________________________\n",
      "25 из 26\n",
      "Корпус: utro-2014.txt.conllu\n",
      "\n",
      "Всего предложений: 1465776\n",
      "\tРазобрано: 1465776\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 3779972\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 14438\n",
      "\tС \"не\": 4834\n",
      "___________________________________________\n",
      "26 из 26\n",
      "Корпус: vogue_2020_2.txt.conllu\n",
      "\n",
      "Всего предложений: 200945\n",
      "\tРазобрано: 200945\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 423014\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 8714\n",
      "\tС \"не\": 2150\n",
      "___________________________________________\n",
      "CPU times: user 2h 41min 27s, sys: 2min 30s, total: 2h 43min 58s\n",
      "Wall time: 2h 45min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_to_dir = './data_conllu/'\n",
    "data_conllu = os.listdir(path_to_dir)\n",
    "\n",
    "result_stat = list()\n",
    "for i in range(len(data_conllu)):\n",
    "    \n",
    "    print(f\"{i + 1} из {len(data_conllu)}\")\n",
    "    \n",
    "    corpus = Corpus('./data_conllu/' + data_conllu[i])\n",
    "    \n",
    "    corpus.save_dict_to_json()\n",
    "    corpus.save_list_to_csv()\n",
    "    \n",
    "    stat = corpus.stat\n",
    "    result_stat.append(stat)    \n",
    "    \n",
    "    print(f\"Корпус: {stat['corpus_name']}\\n\")\n",
    "    print(f\"Всего предложений: {stat['count_sent']}\")\n",
    "    print(f\"\\tРазобрано: {stat['count_parsed_sent']}\")\n",
    "    print(f\"\\tС ошибками парсинга: {stat['count_error_sent']}\\n\")\n",
    "    print(f\"Количество найденных примеров глагольного управления в корпусе = {stat['count_vg']}\")\n",
    "    print('Количество уникальных глаголов в корпусе:')\n",
    "    print(f'\\tБез \"не\": {stat[\"verb_\"]}')\n",
    "    print(f'\\tС \"не\": {stat[\"verb_not\"]}')\n",
    "    print('___________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 из 29\n",
      "Корпус: Foreign_Love_Stories.txt.conllu\n",
      "\n",
      "Всего предложений: 7210321\n",
      "\tРазобрано: 7210321\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 9707513\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 36267\n",
      "\tС \"не\": 11582\n",
      "___________________________________________\n",
      "16 из 29\n",
      "Корпус: might_and_magic.txt.conllu\n",
      "\n",
      "Всего предложений: 689996\n",
      "\tРазобрано: 689996\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 1190847\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 13126\n",
      "\tС \"не\": 4496\n",
      "___________________________________________\n",
      "18 из 29\n",
      "Корпус: nplus1_2020.txt.conllu\n",
      "\n",
      "Всего предложений: 132881\n",
      "\tРазобрано: 132881\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 380140\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 5521\n",
      "\tС \"не\": 1262\n",
      "___________________________________________\n",
      "19 из 29\n",
      "Корпус: orcs_and_dwarfs.txt.conllu\n",
      "\n",
      "Всего предложений: 246028\n",
      "\tРазобрано: 246028\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 405418\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 9870\n",
      "\tС \"не\": 2757\n",
      "___________________________________________\n",
      "20 из 29\n",
      "Корпус: profile_ru.txt.conllu\n",
      "\n",
      "Всего предложений: 330785\n",
      "\tРазобрано: 330785\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 843354\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 11834\n",
      "\tС \"не\": 2033\n",
      "___________________________________________\n",
      "22 из 29\n",
      "Корпус: russian_love_story.txt.conllu\n",
      "\n",
      "Всего предложений: 172480\n",
      "\tРазобрано: 172480\n",
      "\tС ошибками парсинга: 0\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 235537\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 12443\n",
      "\tС \"не\": 2692\n",
      "___________________________________________\n",
      "29 из 29\n",
      "Корпус: vzglyad.txt.conllu\n",
      "\n",
      "Всего предложений: 2054189\n",
      "\tРазобрано: 2054186\n",
      "\tС ошибками парсинга: 3\n",
      "\n",
      "Количество найденных примеров глагольного управления в корпусе = 5735483\n",
      "Количество уникальных глаголов в корпусе:\n",
      "\tБез \"не\": 14614\n",
      "\tС \"не\": 4872\n",
      "___________________________________________\n",
      "CPU times: user 2h 48min 30s, sys: 3min 13s, total: 2h 51min 44s\n",
      "Wall time: 2h 54min 34s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_to_dir = './data_conllu/'\n",
    "data_conllu = os.listdir(path_to_dir)\n",
    "\n",
    "result_stat = list()\n",
    "for i in range(len(data_conllu)):\n",
    "    corpus_name = data_conllu[i].split('.')[:-1]\n",
    "    corpus_name = \".\".join(corpus_name)\n",
    "    if f\"{corpus_name}.csv\" not in data_res or f\"{corpus_name}.json\" not in data_res:        \n",
    "        print(f\"{i + 1} из {len(data_conllu)}\")\n",
    "    \n",
    "        corpus = Corpus('./data_conllu/' + data_conllu[i])\n",
    "\n",
    "        corpus.save_dict_to_json()\n",
    "        corpus.save_list_to_csv()\n",
    "\n",
    "        stat = corpus.stat\n",
    "        result_stat.append(stat)    \n",
    "\n",
    "        print(f\"Корпус: {stat['corpus_name']}\\n\")\n",
    "        print(f\"Всего предложений: {stat['count_sent']}\")\n",
    "        print(f\"\\tРазобрано: {stat['count_parsed_sent']}\")\n",
    "        print(f\"\\tС ошибками парсинга: {stat['count_error_sent']}\\n\")\n",
    "        print(f\"Количество найденных примеров глагольного управления в корпусе = {stat['count_vg']}\")\n",
    "        print('Количество уникальных глаголов в корпусе:')\n",
    "        print(f'\\tБез \"не\": {stat[\"verb_\"]}')\n",
    "        print(f'\\tС \"не\": {stat[\"verb_not\"]}')\n",
    "        print('___________________________________________')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(result_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>corpus_name</th>\n",
       "      <th>count_sent</th>\n",
       "      <th>count_parsed_sent</th>\n",
       "      <th>count_error_sent</th>\n",
       "      <th>count_vg</th>\n",
       "      <th>verb_</th>\n",
       "      <th>verb_not</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Foreign_Love_Stories.txt.conllu</td>\n",
       "      <td>7210321</td>\n",
       "      <td>7210321</td>\n",
       "      <td>0</td>\n",
       "      <td>9707513</td>\n",
       "      <td>36267</td>\n",
       "      <td>11582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>might_and_magic.txt.conllu</td>\n",
       "      <td>689996</td>\n",
       "      <td>689996</td>\n",
       "      <td>0</td>\n",
       "      <td>1190847</td>\n",
       "      <td>13126</td>\n",
       "      <td>4496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nplus1_2020.txt.conllu</td>\n",
       "      <td>132881</td>\n",
       "      <td>132881</td>\n",
       "      <td>0</td>\n",
       "      <td>380140</td>\n",
       "      <td>5521</td>\n",
       "      <td>1262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>orcs_and_dwarfs.txt.conllu</td>\n",
       "      <td>246028</td>\n",
       "      <td>246028</td>\n",
       "      <td>0</td>\n",
       "      <td>405418</td>\n",
       "      <td>9870</td>\n",
       "      <td>2757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>profile_ru.txt.conllu</td>\n",
       "      <td>330785</td>\n",
       "      <td>330785</td>\n",
       "      <td>0</td>\n",
       "      <td>843354</td>\n",
       "      <td>11834</td>\n",
       "      <td>2033</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       corpus_name  count_sent  count_parsed_sent  \\\n",
       "0  Foreign_Love_Stories.txt.conllu     7210321            7210321   \n",
       "1       might_and_magic.txt.conllu      689996             689996   \n",
       "2           nplus1_2020.txt.conllu      132881             132881   \n",
       "3       orcs_and_dwarfs.txt.conllu      246028             246028   \n",
       "4            profile_ru.txt.conllu      330785             330785   \n",
       "\n",
       "   count_error_sent  count_vg  verb_  verb_not  \n",
       "0                 0   9707513  36267     11582  \n",
       "1                 0   1190847  13126      4496  \n",
       "2                 0    380140   5521      1262  \n",
       "3                 0    405418   9870      2757  \n",
       "4                 0    843354  11834      2033  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_excel(\"stat_2.xlsx\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge(a, b, path=None):\n",
    "    \"merges b into a\"\n",
    "    if path is None: path = []\n",
    "    for key in b:\n",
    "        if key in a:\n",
    "            if isinstance(a[key], dict) and isinstance(b[key], dict):\n",
    "                merge(a[key], b[key], path + [str(key)])\n",
    "            else:\n",
    "                a[key] += b[key]\n",
    "        else:\n",
    "            a[key] = b[key]\n",
    "    return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_stat(a, count=None):\n",
    "    if count is None: count = 0\n",
    "    for key in a:\n",
    "        if isinstance(a[key], dict):\n",
    "            count = count_stat(a[key], count)\n",
    "        else:\n",
    "            count += a[key]\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий csv-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreign_Love_Stories.txt.csv\n",
      "articles6_2.csv\n",
      "articles_Vestnik_rayona.csv\n",
      "compulenta-2013.txt.csv\n",
      "detective_for_kidds.txt.csv\n",
      "detective_masters.txt.csv\n",
      "dvnovosti.ru_khab.csv\n",
      "fontanka.txt.csv\n",
      "gazeta-4-ru-2020.txt.csv\n",
      "gazeta_3_ru-2018.csv\n",
      "gorky[ru]_2-2018.csv\n",
      "habarahabr_2017.txt.csv\n",
      "ibusines.txt.csv\n",
      "kosterin72ru.txt.csv\n",
      "membrana.txt.csv\n",
      "might_and_magic.txt.csv\n",
      "naked-science.txt.csv\n",
      "nplus1_2020.txt.csv\n",
      "orcs_and_dwarfs.txt.csv\n",
      "profile_ru.txt.csv\n",
      "rosbalt_2.csv\n",
      "russian_love_story.txt.csv\n",
      "str_fives.txt.csv\n",
      "syntagrus-deeppavlov.txt.csv\n",
      "texts_h_100w.txt.csv\n",
      "texts_m_100w.txt.csv\n",
      "utro-2014.txt.csv\n",
      "vogue_2020_2.txt.csv\n",
      "vzglyad.txt.csv\n"
     ]
    }
   ],
   "source": [
    "path_to_dir = './data/'\n",
    "data = os.listdir(path_to_dir)\n",
    "\n",
    "count_stat_per_dict = 0\n",
    "csv_data_res = None\n",
    "\n",
    "count = 0\n",
    "\n",
    "for filename in data:\n",
    "    if filename[-3:] == \"csv\":\n",
    "        \n",
    "        if csv_data_res is None:\n",
    "            csv_data_res = pd.read_csv(path_to_dir + filename)  \n",
    "            count = len(csv_data_res)\n",
    "        else:\n",
    "            temp_df = pd.read_csv(path_to_dir + filename) \n",
    "            count += len(temp_df)\n",
    "            \n",
    "            csv_data_res = pd.concat([csv_data_res, temp_df], ignore_index = True, axis = 0)\n",
    "    \n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подсчет уникальных сочетаний вида «глагол + предлог + существительное»"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37841081"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(csv_data_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>part</th>\n",
       "      <th>verb</th>\n",
       "      <th>adp</th>\n",
       "      <th>noun</th>\n",
       "      <th>case</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>_</td>\n",
       "      <td>соединить</td>\n",
       "      <td>перед</td>\n",
       "      <td>лицом</td>\n",
       "      <td>Ins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>_</td>\n",
       "      <td>соединить</td>\n",
       "      <td>_</td>\n",
       "      <td>узами</td>\n",
       "      <td>Ins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>_</td>\n",
       "      <td>слушал</td>\n",
       "      <td>_</td>\n",
       "      <td>слова</td>\n",
       "      <td>Acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>_</td>\n",
       "      <td>бросая</td>\n",
       "      <td>_</td>\n",
       "      <td>время</td>\n",
       "      <td>Acc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>_</td>\n",
       "      <td>бросая</td>\n",
       "      <td>_</td>\n",
       "      <td>взгляд</td>\n",
       "      <td>Acc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  part       verb    adp    noun case\n",
       "0    _  соединить  перед   лицом  Ins\n",
       "1    _  соединить      _   узами  Ins\n",
       "2    _     слушал      _   слова  Acc\n",
       "3    _     бросая      _   время  Acc\n",
       "4    _     бросая      _  взгляд  Acc"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_data_res.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_data_res.to_csv('./all_data.csv')  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Общий json-файл"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreign_Love_Stories.txt.json\n",
      "articles6_2.json\n",
      "articles_Vestnik_rayona.json\n",
      "compulenta-2013.txt.json\n",
      "detective_for_kidds.txt.json\n",
      "detective_masters.txt.json\n",
      "dvnovosti.ru_khab.json\n",
      "fontanka.txt.json\n",
      "gazeta-4-ru-2020.txt.json\n",
      "gazeta_3_ru-2018.json\n",
      "gorky[ru]_2-2018.json\n",
      "habarahabr_2017.txt.json\n",
      "ibusines.txt.json\n",
      "kosterin72ru.txt.json\n",
      "membrana.txt.json\n",
      "might_and_magic.txt.json\n",
      "naked-science.txt.json\n",
      "nplus1_2020.txt.json\n",
      "orcs_and_dwarfs.txt.json\n",
      "profile_ru.txt.json\n",
      "rosbalt_2.json\n",
      "russian_love_story.txt.json\n",
      "str_fives.txt.json\n",
      "syntagrus-deeppavlov.txt.json\n",
      "texts_h_100w.txt.json\n",
      "texts_m_100w.txt.json\n",
      "utro-2014.txt.json\n",
      "vogue_2020_2.txt.json\n",
      "vzglyad.txt.json\n"
     ]
    }
   ],
   "source": [
    "path_to_dir = './data/'\n",
    "data = os.listdir(path_to_dir)\n",
    "\n",
    "count_stat_per_dict = 0\n",
    "json_data_res = None\n",
    "\n",
    "for filename in data:\n",
    "    if filename[-4:] == \"json\":\n",
    "        \n",
    "        with open(path_to_dir + filename, 'r', encoding='UTF-8') as f:\n",
    "            json_data = json.load(f)\n",
    "            \n",
    "        count_stat_per_dict += count_stat(json_data)\n",
    "        \n",
    "        if json_data_res is None:\n",
    "            json_data_res = json_data.copy()\n",
    "        else:\n",
    "            json_data_res = merge(json_data_res, json_data)  \n",
    "    \n",
    "        print(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "37841081"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_stat(json_data_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35591133"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_stat(json_data_res['_'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2249948"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_stat(json_data_res['не'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./all_data.json', 'w', encoding='UTF-8') as f:\n",
    "    json.dump(json_data_res, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Глаголы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./all_data.json', 'r', encoding='UTF-8') as f:\n",
    "    json_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "156"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_stat(json_data['_']['бежать']['на']['Loc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "for key in json_data:\n",
    "    for verb in json_data[key]:\n",
    "        if count_stat(json_data[key][verb]) == 1:\n",
    "            b.add(verb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24057"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['желайт',\n",
       " 'искажашие',\n",
       " 'путовать',\n",
       " 'пронеслисить',\n",
       " 'ытоптать',\n",
       " 'растерзовать',\n",
       " 'расковаться',\n",
       " 'истаиалый',\n",
       " 'заненсный',\n",
       " 'сцениать']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(b)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 24281 глаголов, которые встретились в корпусе всего один раз. Это могут быть как редкие глаголы, так и глаголы с ошибками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = set(json_data[\"_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.update(json_data[\"не\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66462"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(a) #Всего уникальных глаголов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65093"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data[\"_\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16781"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(json_data[\"не\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1369\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for verb in json_data[\"не\"]:\n",
    "    if verb not in json_data[\"_\"]:\n",
    "        count += 1\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66462"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1369 + 49681 + 15412"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# считаем статистику по: глагол + предлог + падеж"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_data = json_data[\"не\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in json_data: \n",
    "    for verb in json_data[part]:\n",
    "        for adp in json_data[part][verb]:\n",
    "            for case in json_data[part][verb][adp]:\n",
    "                if case != 'Nom':\n",
    "                    string = f\"{verb}_{adp}_{case}\"\n",
    "                    res.add(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'откупаться_с_Gen'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "423196"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_2 = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in json_data: \n",
    "    for verb in json_data[part]:\n",
    "        for adp in json_data[part][verb]:\n",
    "            for case in json_data[part][verb][adp]:\n",
    "                for noun in json_data[part][verb][adp][case]:\n",
    "                    if case != 'Nom':\n",
    "                        string = f\"{verb}_{adp}_{case}_{noun}\"\n",
    "                        res_2.add(string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6528983"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_3 = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "for part in json_data: \n",
    "    for verb in json_data[part]:\n",
    "        for adp in json_data[part][verb]:\n",
    "            for case in json_data[part][verb][adp]:\n",
    "                for noun in json_data[part][verb][adp][case]:\n",
    "                    res_3.add(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "196128"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(res_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['_', 'по', 'в', 'через', 'мимо', 'при', 'у', 'от', 'из', 'с', 'к', 'на', 'впереди', 'под', 'после', 'за', 'без', 'среди', 'о', 'до', 'над', 'из-под', 'вдоль', 'сквозь', 'вокруг', 'посреди', 'позади', 'перед', 'для', 'из-за', 'между', 'меж', 'посередине', 'ради', 'плюс', 'около', 'против', 'спустя', 'вместо', 'порядок', 'накануне', 'помимо', 'вопреки', 'согласно'])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data_res[\"_\"][\"бежать\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acc': {'полиция': 2,\n",
       "  'подъезд': 1,\n",
       "  'школа': 1,\n",
       "  'поисковик': 1,\n",
       "  'вода': 1,\n",
       "  'теплица': 1,\n",
       "  'время': 3,\n",
       "  'атака': 1,\n",
       "  'аптека': 1},\n",
       " 'Loc': {'кроссовок': 1, 'комментарий': 1, 'ступор': 1, 'страх': 1},\n",
       " 'Gen': {'реклама': 1}}"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data_res[\"не\"][\"бежать\"][\"в\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Acc': {'деревня': 1,\n",
       "  'куст': 1,\n",
       "  'дорога': 7,\n",
       "  'лабиринт': 1,\n",
       "  'поле': 5,\n",
       "  'лес': 8,\n",
       "  'мгновение': 1,\n",
       "  'дворик': 1,\n",
       "  'двор': 4,\n",
       "  'пара': 2,\n",
       "  'сад': 1,\n",
       "  'газон': 1,\n",
       "  'заросль': 2,\n",
       "  'снег': 1,\n",
       "  'люк': 1,\n",
       "  'лужайка': 3,\n",
       "  'холл': 4,\n",
       "  'мыс': 1,\n",
       "  'граница': 4,\n",
       "  'библиотека': 1,\n",
       "  'крыша': 1,\n",
       "  'дом': 1,\n",
       "  'долина': 1,\n",
       "  'цепь': 1,\n",
       "  'луг': 4,\n",
       "  'год': 3,\n",
       "  'путь': 1,\n",
       "  'кустарник': 1,\n",
       "  'пустырь': 1,\n",
       "  'ход': 4,\n",
       "  'шоссе': 1,\n",
       "  'поляна': 1,\n",
       "  'роща': 1,\n",
       "  'этаж': 1,\n",
       "  'площадка': 1,\n",
       "  'ряд': 1,\n",
       "  'переход': 1,\n",
       "  'окоп': 1,\n",
       "  'полянка': 1,\n",
       "  'стена': 1,\n",
       "  'дверь': 1,\n",
       "  'время': 1,\n",
       "  'час': 1,\n",
       "  'город': 1,\n",
       "  'терминал': 1,\n",
       "  'капилляр': 1,\n",
       "  'минута': 1,\n",
       "  'площадь': 1,\n",
       "  'окно': 1},\n",
       " 'Gen': {'минута': 4, 'секунда': 2}}"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "json_data_res[\"_\"][\"бежать\"][\"через\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Считаю статистику по корпусам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Corpus_2:\n",
    "    \n",
    "    def __init__(self, filename):\n",
    "        self.filename = filename\n",
    "        self.dict_of_lemmas = dict()\n",
    "        self.list_of_forms = list()\n",
    "        self.count_parsed = 0\n",
    "        self.count_error = 0\n",
    "        \n",
    "        self.stat = 0\n",
    "        \n",
    "        self.__read_conllu_data__(filename)\n",
    "        \n",
    "    def __parse_conllu__(self, text):\n",
    "        try: \n",
    "            result = [tokenlist for tokenlist in conllu.parse(text)]\n",
    "            return result[0]\n",
    "        except:\n",
    "            return None ## сюда можно подставить свой собственный разбор\n",
    "        \n",
    "    def __find_verb_government__(self, sent):\n",
    "        for token in sent:\n",
    "            if token['upos'] != 'PUNCT':\n",
    "                self.stat += 1\n",
    "        \n",
    "    def __read_conllu_data__(self, filename):\n",
    "        with open(filename, 'r', encoding='UTF-8') as f:  \n",
    "            flag = False\n",
    "            temp_list = list()\n",
    "\n",
    "            while True: \n",
    "                line = f.readline()\n",
    "                if not line:  # достигли конца файла\n",
    "                    parse_result = self.__parse_conllu__(\"\".join(temp_list))\n",
    "                    if parse_result is not None:\n",
    "                        self.__find_verb_government__(parse_result)\n",
    "                        self.count_parsed += 1\n",
    "                    else:\n",
    "                        self.count_error += 1\n",
    "                    return 0\n",
    "                if line[:6] == \"# text\":\n",
    "                    if flag is False:  # начинаем считывать новое предложение\n",
    "                        flag = True\n",
    "                    else:  # достигли конца разбора предложения\n",
    "                        flag = False\n",
    "                        parse_result = self.__parse_conllu__(\"\".join(temp_list))\n",
    "                        if parse_result is not None:\n",
    "                            self.__find_verb_government__(parse_result)\n",
    "                            self.count_parsed += 1\n",
    "                        else:\n",
    "                            self.count_error += 1\n",
    "                        temp_list = list()\n",
    "                temp_list.append(line)\n",
    "                \n",
    "    def __count_verb__(self, part):\n",
    "        try:\n",
    "            count = len(self.dict_of_lemmas[part])\n",
    "        except:\n",
    "            count = 0\n",
    "        return count\n",
    "                \n",
    "    def __calculate__(self):       \n",
    "        result_dict = {\n",
    "            \"corpus_name\": self.filename.split('/')[-1],\n",
    "            \"count_sent\" : self.count_parsed + self.count_error,\n",
    "            \"count_parsed_sent\": self.count_parsed, \n",
    "            \"count_error_sent\": self.count_error,\n",
    "            \"count_vg\": len(self.list_of_forms), \n",
    "            \"verb_\": self.__count_verb__(\"_\"), \n",
    "            \"verb_not\": self.__count_verb__(\"не\") \n",
    "        }\n",
    "        return result_dict\n",
    "    \n",
    "    def __new_filename__(self, ext):\n",
    "        parts = self.filename.split('conllu')\n",
    "        new_filename = parts[0][:-1] + parts[1] + ext\n",
    "        return new_filename\n",
    "        \n",
    "    def save_dict_to_json(self, json_filename=None):\n",
    "        if json_filename is None:\n",
    "            json_filename = self.__new_filename__('json')\n",
    "        \n",
    "        with open(json_filename, 'w', encoding='UTF-8') as f:\n",
    "            json.dump(self.dict_of_lemmas, f)\n",
    "    \n",
    "    def save_list_to_csv(self, csv_filename=None):\n",
    "        if csv_filename is None:\n",
    "            csv_filename = self.__new_filename__('csv')\n",
    "            \n",
    "        keys = self.list_of_forms[0].keys()\n",
    "        \n",
    "        with open(csv_filename, 'w', encoding='UTF-8', newline='') as f:\n",
    "            dict_writer = csv.DictWriter(f, keys)\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(self.list_of_forms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_dir = './data_conllu/'\n",
    "data_conllu = os.listdir(path_to_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 9min 8s, sys: 7.19 s, total: 9min 16s\n",
      "Wall time: 9min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "corpus = Corpus_2('./data_conllu/' + data_conllu[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11028843"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus.stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#8953117 - без пунктуации"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 из 29\n",
      "Foreign_Love_Stories.txt.conllu 73343266\n",
      "2 из 29\n",
      "articles6_2.conllu 193651\n",
      "3 из 29\n",
      "articles_Vestnik_rayona.conllu 156367\n",
      "4 из 29\n",
      "compulenta-2013.txt.conllu 8953117\n",
      "5 из 29\n",
      "detective_for_kidds.txt.conllu 5445601\n",
      "6 из 29\n",
      "detective_masters.txt.conllu 12548302\n",
      "7 из 29\n",
      "dvnovosti.ru_khab.conllu 192751\n",
      "8 из 29\n",
      "fontanka.txt.conllu 16244474\n",
      "9 из 29\n",
      "gazeta-4-ru-2020.txt.conllu 9818350\n",
      "10 из 29\n",
      "gazeta_3_ru-2018.conllu 4371913\n",
      "11 из 29\n",
      "gorky[ru]_2-2018.conllu 1242284\n",
      "12 из 29\n",
      "habarahabr_2017.txt.conllu 14924070\n",
      "13 из 29\n",
      "ibusines.txt.conllu 5384745\n",
      "14 из 29\n",
      "kosterin72ru.txt.conllu 9219897\n",
      "15 из 29\n",
      "membrana.txt.conllu 4046765\n",
      "16 из 29\n",
      "might_and_magic.txt.conllu 7953042\n",
      "17 из 29\n",
      "naked-science.txt.conllu 3621288\n",
      "18 из 29\n",
      "nplus1_2020.txt.conllu 2280852\n",
      "19 из 29\n",
      "orcs_and_dwarfs.txt.conllu 2590083\n",
      "20 из 29\n",
      "profile_ru.txt.conllu 5127225\n",
      "21 из 29\n",
      "rosbalt_2.conllu 3603819\n",
      "22 из 29\n",
      "russian_love_story.txt.conllu 1764424\n",
      "23 из 29\n",
      "str_fives.txt.conllu 451257\n",
      "24 из 29\n",
      "syntagrus-deeppavlov.txt.conllu 449735\n",
      "25 из 29\n",
      "texts_h_100w.txt.conllu 971519\n",
      "26 из 29\n",
      "texts_m_100w.txt.conllu 1050514\n",
      "27 из 29\n",
      "utro-2014.txt.conllu 24089792\n",
      "28 из 29\n",
      "vogue_2020_2.txt.conllu 3253834\n",
      "29 из 29\n",
      "vzglyad.txt.conllu 36341617\n",
      "CPU times: user 5h 51min 18s, sys: 2min 25s, total: 5h 53min 44s\n",
      "Wall time: 5h 54min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "path_to_dir = './data_conllu/'\n",
    "data_conllu = os.listdir(path_to_dir)\n",
    "\n",
    "result_stat = dict()\n",
    "for i in range(len(data_conllu)):\n",
    "    corpus_name = data_conllu[i].split('.')[:-1]\n",
    "    corpus_name = \".\".join(corpus_name)      \n",
    "    \n",
    "    print(f\"{i + 1} из {len(data_conllu)}\")\n",
    "\n",
    "    corpus = Corpus_2('./data_conllu/' + data_conllu[i])\n",
    "    stat = corpus.stat\n",
    "    result_stat[data_conllu[i]] = stat\n",
    "    print(data_conllu[i], stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "259634554\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for key in result_stat:\n",
    "    count += result_stat[key]\n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Foreign_Love_Stories.txt.conllu 28.25\n",
      "articles6_2.conllu 0.07\n",
      "articles_Vestnik_rayona.conllu 0.06\n",
      "compulenta-2013.txt.conllu 3.45\n",
      "detective_for_kidds.txt.conllu 2.1\n",
      "detective_masters.txt.conllu 4.83\n",
      "dvnovosti.ru_khab.conllu 0.07\n",
      "fontanka.txt.conllu 6.26\n",
      "gazeta-4-ru-2020.txt.conllu 3.78\n",
      "gazeta_3_ru-2018.conllu 1.68\n",
      "gorky[ru]_2-2018.conllu 0.48\n",
      "habarahabr_2017.txt.conllu 5.75\n",
      "ibusines.txt.conllu 2.07\n",
      "kosterin72ru.txt.conllu 3.55\n",
      "membrana.txt.conllu 1.56\n",
      "might_and_magic.txt.conllu 3.06\n",
      "naked-science.txt.conllu 1.39\n",
      "nplus1_2020.txt.conllu 0.88\n",
      "orcs_and_dwarfs.txt.conllu 1.0\n",
      "profile_ru.txt.conllu 1.97\n",
      "rosbalt_2.conllu 1.39\n",
      "russian_love_story.txt.conllu 0.68\n",
      "str_fives.txt.conllu 0.17\n",
      "syntagrus-deeppavlov.txt.conllu 0.17\n",
      "texts_h_100w.txt.conllu 0.37\n",
      "texts_m_100w.txt.conllu 0.4\n",
      "utro-2014.txt.conllu 9.28\n",
      "vogue_2020_2.txt.conllu 1.25\n",
      "vzglyad.txt.conllu 14.0\n"
     ]
    }
   ],
   "source": [
    "per = 0\n",
    "for key in result_stat:\n",
    "    temp = round(result_stat[key] / count * 100, 2)\n",
    "    print(key, temp)\n",
    "    per += temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Foreign_Love_Stories.txt.conllu': 73343266,\n",
       " 'articles6_2.conllu': 193651,\n",
       " 'articles_Vestnik_rayona.conllu': 156367,\n",
       " 'compulenta-2013.txt.conllu': 8953117,\n",
       " 'detective_for_kidds.txt.conllu': 5445601,\n",
       " 'detective_masters.txt.conllu': 12548302,\n",
       " 'dvnovosti.ru_khab.conllu': 192751,\n",
       " 'fontanka.txt.conllu': 16244474,\n",
       " 'gazeta-4-ru-2020.txt.conllu': 9818350,\n",
       " 'gazeta_3_ru-2018.conllu': 4371913,\n",
       " 'gorky[ru]_2-2018.conllu': 1242284,\n",
       " 'habarahabr_2017.txt.conllu': 14924070,\n",
       " 'ibusines.txt.conllu': 5384745,\n",
       " 'kosterin72ru.txt.conllu': 9219897,\n",
       " 'membrana.txt.conllu': 4046765,\n",
       " 'might_and_magic.txt.conllu': 7953042,\n",
       " 'naked-science.txt.conllu': 3621288,\n",
       " 'nplus1_2020.txt.conllu': 2280852,\n",
       " 'orcs_and_dwarfs.txt.conllu': 2590083,\n",
       " 'profile_ru.txt.conllu': 5127225,\n",
       " 'rosbalt_2.conllu': 3603819,\n",
       " 'russian_love_story.txt.conllu': 1764424,\n",
       " 'str_fives.txt.conllu': 451257,\n",
       " 'syntagrus-deeppavlov.txt.conllu': 449735,\n",
       " 'texts_h_100w.txt.conllu': 971519,\n",
       " 'texts_m_100w.txt.conllu': 1050514,\n",
       " 'utro-2014.txt.conllu': 24089792,\n",
       " 'vogue_2020_2.txt.conllu': 3253834,\n",
       " 'vzglyad.txt.conllu': 36341617}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_stat"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
